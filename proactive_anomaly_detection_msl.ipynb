{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e626ca-8c4d-4c92-933a-2b4efc8ebbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db09d25-a593-47a3-8a25-a88cfcd1afe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 2070\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9726e600-be00-41a4-83e1-fd0d2f26cbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SMAP' 'MSL']\n",
      "['M-6.npy', 'M-1.npy', 'M-2.npy', 'S-2.npy', 'P-10.npy', 'T-4.npy', 'T-5.npy', 'F-7.npy', 'M-3.npy', 'M-4.npy', 'M-5.npy', 'P-15.npy', 'C-1.npy', 'C-2.npy', 'T-12.npy', 'T-13.npy', 'F-4.npy', 'F-5.npy', 'D-14.npy', 'T-9.npy', 'P-14.npy', 'T-8.npy', 'P-11.npy', 'D-15.npy', 'D-16.npy', 'M-7.npy', 'F-8.npy']\n"
     ]
    }
   ],
   "source": [
    "# csv_path = '/content/drive/MyDrive/rupa/archive/labeled_anomalies.csv'\n",
    "csv_path = r'C:\\Users\\skhandaker\\OneDrive - Oklahoma City University\\Documents\\Anomaly Detection Paper\\rupa\\archive\\labeled_anomalies.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(df[\"spacecraft\"].unique())\n",
    "\n",
    "m_files = [f\"{chan_id}.npy\" for chan_id in df.loc[df['spacecraft']=='MSL', 'chan_id']]\n",
    "\n",
    "print(m_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346cd914-a601-4016-ad15-80ce1240190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated shape (rows): (73729, 55)\n"
     ]
    }
   ],
   "source": [
    "# test_dir = '/content/drive/MyDrive/rupa/archive/data/data/test'\n",
    "test_dir = r'C:\\Users\\skhandaker\\OneDrive - Oklahoma City University\\Documents\\Anomaly Detection Paper\\rupa\\archive\\data\\data\\test'\n",
    "\n",
    "# m_files = sorted(f for f in os.listdir(test_dir) if f.endswith('.npy') and f.startswith('M'))\n",
    "\n",
    "data_list = [np.load(os.path.join(test_dir, fname)) for fname in m_files]\n",
    "\n",
    "X = np.concatenate(data_list, axis=0)\n",
    "\n",
    "print(\"Concatenated shape (rows):\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7c30e22-436f-4664-8582-cd4698f1b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '0']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '1']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '2']\n",
      " ...\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'F-8' '2484']\n",
      " ['-0.8695652173913043' '0.0' '0.0' ... '0.0' 'F-8' '2485']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'F-8' '2486']]\n"
     ]
    }
   ],
   "source": [
    "test_dir = r'C:\\Users\\skhandaker\\OneDrive - Oklahoma City University\\Documents\\Anomaly Detection Paper\\rupa\\archive\\data\\data\\test'\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for fname in m_files:\n",
    "    file_path = os.path.join(test_dir, fname)\n",
    "    arr = np.load(file_path)\n",
    "    chan_id = fname[:-4]\n",
    "    chan_ids = np.full((arr.shape[0], 1), chan_id)\n",
    "    row_numbers = np.arange(arr.shape[0]).reshape(-1, 1)\n",
    "    combined = np.hstack([arr, chan_ids, row_numbers])\n",
    "\n",
    "    data_list.append(combined)\n",
    "\n",
    "X = np.vstack(data_list)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea34da66-4a1c-49c3-9a15-8ef4a963d225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '0']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '1']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '2']\n",
      " ...\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'F-8' '2484']\n",
      " ['-0.8695652173913043' '0.0' '0.0' ... '0.0' 'F-8' '2485']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'F-8' '2486']]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9f978eb-59bc-48c6-b0f6-7abf6d74ba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique embeddings: 25478\n",
      "Total time steps: 73729\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# all_rows = []\n",
    "\n",
    "# for f in m_files:\n",
    "#     data = np.load(os.path.join(test_dir, f))\n",
    "#     all_rows.append(data)\n",
    "\n",
    "# combined = np.concatenate(all_rows, axis=0).astype(np.float32)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(X[:, :55], dtype=np.float32)\n",
    "unique_embeddings = df.drop_duplicates()\n",
    "\n",
    "print(\"Unique embeddings:\", len(unique_embeddings))\n",
    "print(\"Total time steps:\", len(df))\n",
    "\n",
    "print(type(df))\n",
    "print(type(unique_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b798862b-21d9-44b2-ad62-f0b1be5dcb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1    2    3    4    5    6    7    8    9   ...   45   46  \\\n",
      "0     -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1     -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2     -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3     -1.000000  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4     -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "73324  1.043478  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "73425  0.260870  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "73481 -0.956522  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "73564 -0.913043  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "73616 -0.913043  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "        47   48   49   50   51   52   53   54  \n",
      "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "73324  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "73425  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "73481  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "73564  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "73616  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[25478 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "print(unique_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12f7e02f-4c7c-410d-8de9-81fc155e3c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1    2    3    4    5    6    7    8    9   ...   45   46  \\\n",
      "0     -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1     -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2     -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3     -1.000000  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4     -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "73724 -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "73725 -0.956522  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "73726 -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "73727 -0.869565  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "73728 -1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "        47   48   49   50   51   52   53   54  \n",
      "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "73724  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "73725  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "73726  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "73727  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "73728  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[73729 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26856e60-a052-44a2-aa14-dff5f2ceff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "  \"vocab_size\": 25500, # Vocabulary size\n",
    "  \"context_length\": 64, # Context length\n",
    "  \"emb_dim\": 55, # Embedding dimension\n",
    "  \"n_heads\": 5, # Number of attention heads\n",
    "  \"n_layers\": 12, # Number of layers\n",
    "  \"drop_rate\": 0.1, # Dropout rate\n",
    "  \"qkv_bias\": False # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "154ad776-5b2f-476b-8d85-332763a7d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    " def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "  super().__init__()\n",
    "  assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "  self.d_out = d_out\n",
    "  self.num_heads = num_heads\n",
    "  self.head_dim = d_out // num_heads\n",
    "  self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.out_proj = nn.Linear(d_out, d_out)\n",
    "  self.dropout = nn.Dropout(dropout)\n",
    "  self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    " def forward(self, x):\n",
    "  b, num_tokens, d_in = x.shape\n",
    "  keys = self.W_key(x)\n",
    "  queries = self.W_query(x)\n",
    "  values = self.W_value(x)\n",
    "  keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "  values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "  queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "  keys = keys.transpose(1, 2)\n",
    "  queries = queries.transpose(1, 2)\n",
    "  values = values.transpose(1, 2)\n",
    "  attn_scores = queries @ keys.transpose(2, 3)\n",
    "  mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "  attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "  attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "  attn_weights = self.dropout(attn_weights)\n",
    "  context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "  context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "  context_vec = self.out_proj(context_vec)\n",
    "  return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0d2c6f0-38e4-4dcd-be5d-90409640d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b52377b6-a066-4285-8046-57d831b33ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), GELU(), nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f90b4bf5-3c6b-41f8-8e4f-aa35817fad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "  def __init__(self, emb_dim):\n",
    "    super().__init__()\n",
    "    self.eps = 1e-5\n",
    "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "  def forward(self, x):\n",
    "    mean = x.mean(dim=-1, keepdim=True)\n",
    "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "    return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "988cb1f0-bcfd-4f67-8d99-85d8a9cd6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.att = MultiHeadAttention(d_in=cfg[\"emb_dim\"], d_out=cfg[\"emb_dim\"], context_length=cfg[\"context_length\"], num_heads=cfg[\"n_heads\"], dropout=cfg[\"drop_rate\"], qkv_bias=cfg[\"qkv_bias\"])\n",
    "    self.ff = FeedForward(cfg)\n",
    "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "  def forward(self, x):\n",
    "    shortcut = x\n",
    "    x = self.norm1(x)\n",
    "    x = self.att(x)\n",
    "    x = self.drop_shortcut(x)\n",
    "    x = x + shortcut\n",
    "    shortcut = x\n",
    "    x = self.norm2(x)\n",
    "    x = self.ff(x)\n",
    "    x = self.drop_shortcut(x)\n",
    "    x = x + shortcut\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "059fe16b-4450-4898-974a-2f1bd440aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_unique_embeddings = unique_embeddings.values\n",
    "emb_tuples = [tuple(row) for row in c_unique_embeddings]\n",
    "emb2idx = {emb: idx for idx, emb in enumerate(emb_tuples)}\n",
    "def get_embedding_ids(batch):\n",
    "    batch_np = batch.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "    B, L, D = batch_np.shape\n",
    "    ids = np.full((B, L), -1, dtype=int)\n",
    "\n",
    "    for i in range(B):\n",
    "        for j in range(L):\n",
    "            ids[i, j] = emb2idx.get(tuple(batch_np[i, j]), -1)\n",
    "\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "737c5fea-fc9e-448c-bd5d-c2820305e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    # self.cfg = cfg\n",
    "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "    self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "  def forward(self, in_idx):\n",
    "    global device\n",
    "    batch_size, seq_len, _ = in_idx.shape\n",
    "    in_idx = get_embedding_ids(in_idx)\n",
    "\n",
    "    in_idx = torch.from_numpy(in_idx).long().to(device)\n",
    "\n",
    "    tok_embeds = self.tok_emb(in_idx)\n",
    "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "    x = tok_embeds + pos_embeds\n",
    "    x = self.drop_emb(x)\n",
    "    x = self.trf_blocks(x)\n",
    "    x = self.final_norm(x)\n",
    "    logits = self.out_head(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71ee7b07-68cf-47ba-87bd-0b30bf724bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(X))\n",
    "train_data = X[:split_idx]\n",
    "val_data = X[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dc13df4-1fd8-44f9-ae3c-ce7b1db7f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '0']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '1']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'M-6' '2']\n",
      " ...\n",
      " ['1.144377602961592' '0.0' '0.0' ... '0.0' 'D-15' '1616']\n",
      " ['1.1434521055067097' '0.0' '0.0' ... '0.0' 'D-15' '1617']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'D-15' '1618']]\n",
      "[['1.1416011105969461' '0.0' '0.0' ... '0.0' 'D-15' '1619']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'D-15' '1620']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'D-15' '1621']\n",
      " ...\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'F-8' '2484']\n",
      " ['-0.8695652173913043' '0.0' '0.0' ... '0.0' 'F-8' '2485']\n",
      " ['-1.0' '0.0' '0.0' ... '0.0' 'F-8' '2486']]\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(val_data))\n",
    "print(train_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0d41f87-e61e-4c5f-bb2e-2f3aee072618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "  def __init__(self, txt, max_length, stride):\n",
    "    self.input_ids = []\n",
    "    self.target_ids = []\n",
    "\n",
    "    # for txt in txts:\n",
    "    for i in range(0, len(txt) - max_length, stride):\n",
    "      input_chunk = txt[i:i + max_length]\n",
    "      target_chunk = txt[i + 1: i + max_length + 1]\n",
    "      self.input_ids.append(torch.tensor(input_chunk))\n",
    "      self.target_ids.append(torch.tensor(target_chunk))\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1715d11-c246-4b2d-9182-989bc9baf57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "  dataset = GPTDatasetV1(txt, max_length, stride)\n",
    "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62c9d170-b748-46d1-92ab-6c57249c4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numeric = train_data[:, :55].astype(np.float32)\n",
    "val_numeric = val_data[:, :55].astype(np.float32)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "  train_numeric,\n",
    "  batch_size=256,\n",
    "  max_length=GPT_CONFIG[\"context_length\"],\n",
    "  stride=GPT_CONFIG[\"context_length\"],\n",
    "  drop_last=True,\n",
    "  shuffle=True,\n",
    "  num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "  val_numeric,\n",
    "  batch_size=256,\n",
    "  max_length=GPT_CONFIG[\"context_length\"],\n",
    "  stride=GPT_CONFIG[\"context_length\"],\n",
    "  drop_last=False,\n",
    "  shuffle=False,\n",
    "  num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e6fe794-967e-4d21-8c6c-789adbe1dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_emb_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_emb_batch = target_emb_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    target_ids = get_embedding_ids(target_emb_batch)\n",
    "    target_ids = torch.from_numpy(target_ids).long().to(device)\n",
    "    B, L, V = logits.size()\n",
    "    logits_flat  = logits.view(B * L, V)\n",
    "    targets_flat = target_ids.view(B * L)\n",
    "    loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23343994-61f4-4981-9474-a198c04c65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "  total_loss = 0\n",
    "  if len(data_loader) == 0:\n",
    "    return float(\"nan\")\n",
    "  elif num_batches is None:\n",
    "    num_batches = len(data_loader)\n",
    "  else:\n",
    "    num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "    if i < num_batches:\n",
    "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "      total_loss += loss.item()\n",
    "    else:\n",
    "      break\n",
    "\n",
    "  return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0334e14-7dc4-4bb5-83f7-6c5713568e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "  model.train()\n",
    "  return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b24bc405-5da0-47d3-8dc6-6149871cf77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "  tokens_seen, global_step = 0, -1\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for input_batch, target_batch in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      tokens_seen += input_batch.numel()\n",
    "      global_step += 1\n",
    "\n",
    "      if global_step % eval_freq == 0:\n",
    "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        track_tokens_seen.append(tokens_seen)\n",
    "        print(f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "  return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d42c602a-aa45-4a6b-b8c5-09c08767281d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.279, Val loss 10.181\n",
      "Ep 2 (Step 000005): Train loss 9.956, Val loss 9.689\n",
      "Ep 3 (Step 000010): Train loss 9.758, Val loss 9.489\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m optimizer = torch.optim.AdamW(\n\u001b[32m      6\u001b[39m   model.parameters(),\n\u001b[32m      7\u001b[39m   lr=\u001b[32m0.0004\u001b[39m, weight_decay=\u001b[32m0.1\u001b[39m\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m num_epochs = \u001b[32m100\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m train_losses, val_losses, tokens_seen = \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m  \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain_model_simple\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter)\u001b[39m\n\u001b[32m      7\u001b[39m optimizer.zero_grad()\n\u001b[32m      8\u001b[39m loss = calc_loss_batch(input_batch, target_batch, model, device)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m optimizer.step()\n\u001b[32m     11\u001b[39m tokens_seen += input_batch.numel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3_new\\envs\\dcgan\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3_new\\envs\\dcgan\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3_new\\envs\\dcgan\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "  model.parameters(),\n",
    "  lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 100\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "  model, train_loader, val_loader, optimizer, device,\n",
    "  num_epochs=num_epochs, eval_freq=5, eval_iter=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71f9532e-7dd5-4c1a-9df7-f7c77bf38470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "chan_id                                                     P-1\n",
      "spacecraft                                                 SMAP\n",
      "anomaly_sequences    [[2149, 2349], [4536, 4844], [3539, 3779]]\n",
      "class                      [contextual, contextual, contextual]\n",
      "num_values                                                 8505\n",
      "Name: 0, dtype: object\n",
      "1\n",
      "chan_id                         S-1\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5300, 5747]]\n",
      "class                       [point]\n",
      "num_values                     7331\n",
      "Name: 1, dtype: object\n",
      "2\n",
      "chan_id                                       E-1\n",
      "spacecraft                                   SMAP\n",
      "anomaly_sequences    [[5000, 5030], [5610, 6086]]\n",
      "class                    [contextual, contextual]\n",
      "num_values                                   8516\n",
      "Name: 2, dtype: object\n",
      "3\n",
      "chan_id                         E-2\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5598, 6995]]\n",
      "class                       [point]\n",
      "num_values                     8532\n",
      "Name: 3, dtype: object\n",
      "4\n",
      "chan_id                         E-3\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5094, 8306]]\n",
      "class                       [point]\n",
      "num_values                     8307\n",
      "Name: 4, dtype: object\n",
      "5\n",
      "chan_id                         E-4\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5450, 8261]]\n",
      "class                       [point]\n",
      "num_values                     8354\n",
      "Name: 5, dtype: object\n",
      "6\n",
      "chan_id                         E-5\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5600, 5920]]\n",
      "class                       [point]\n",
      "num_values                     8294\n",
      "Name: 6, dtype: object\n",
      "7\n",
      "chan_id                         E-6\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5610, 5675]]\n",
      "class                       [point]\n",
      "num_values                     8300\n",
      "Name: 7, dtype: object\n",
      "8\n",
      "chan_id                         E-7\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5394, 5674]]\n",
      "class                       [point]\n",
      "num_values                     8310\n",
      "Name: 8, dtype: object\n",
      "9\n",
      "chan_id                         E-8\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5400, 6022]]\n",
      "class                       [point]\n",
      "num_values                     8532\n",
      "Name: 9, dtype: object\n",
      "10\n",
      "chan_id                         E-9\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5550, 5900]]\n",
      "class                       [point]\n",
      "num_values                     8302\n",
      "Name: 10, dtype: object\n",
      "11\n",
      "chan_id                                      E-10\n",
      "spacecraft                                   SMAP\n",
      "anomaly_sequences    [[5000, 5050], [5601, 5871]]\n",
      "class                    [contextual, contextual]\n",
      "num_values                                   8505\n",
      "Name: 11, dtype: object\n",
      "12\n",
      "chan_id                                      E-11\n",
      "spacecraft                                   SMAP\n",
      "anomaly_sequences    [[5000, 5050], [5614, 5857]]\n",
      "class                    [contextual, contextual]\n",
      "num_values                                   8514\n",
      "Name: 12, dtype: object\n",
      "13\n",
      "chan_id                                      E-12\n",
      "spacecraft                                   SMAP\n",
      "anomaly_sequences    [[5610, 6141], [5000, 5050]]\n",
      "class                    [contextual, contextual]\n",
      "num_values                                   8512\n",
      "Name: 13, dtype: object\n",
      "14\n",
      "chan_id                                                    E-13\n",
      "spacecraft                                                 SMAP\n",
      "anomaly_sequences    [[5309, 5410], [5600, 5640], [6449, 6569]]\n",
      "class                      [contextual, contextual, contextual]\n",
      "num_values                                                 8640\n",
      "Name: 14, dtype: object\n",
      "15\n",
      "chan_id                         A-1\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4690, 4774]]\n",
      "class                       [point]\n",
      "num_values                     8640\n",
      "Name: 15, dtype: object\n",
      "16\n",
      "chan_id                         D-1\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5250, 8508]]\n",
      "class                       [point]\n",
      "num_values                     8509\n",
      "Name: 16, dtype: object\n",
      "17\n",
      "chan_id                         P-2\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5350, 6575]]\n",
      "class                       [point]\n",
      "num_values                     8209\n",
      "Name: 17, dtype: object\n",
      "18\n",
      "chan_id                         P-3\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5401, 6736]]\n",
      "class                       [point]\n",
      "num_values                     8493\n",
      "Name: 18, dtype: object\n",
      "19\n",
      "chan_id                         D-2\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4319, 8536]]\n",
      "class                       [point]\n",
      "num_values                     8595\n",
      "Name: 19, dtype: object\n",
      "20\n",
      "chan_id                         D-3\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5225, 8500]]\n",
      "class                       [point]\n",
      "num_values                     8640\n",
      "Name: 20, dtype: object\n",
      "21\n",
      "chan_id                         D-4\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5225, 8472]]\n",
      "class                       [point]\n",
      "num_values                     8473\n",
      "Name: 21, dtype: object\n",
      "22\n",
      "chan_id                         A-2\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4450, 4560]]\n",
      "class                  [contextual]\n",
      "num_values                     7914\n",
      "Name: 22, dtype: object\n",
      "23\n",
      "chan_id                         A-3\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4575, 4760]]\n",
      "class                  [contextual]\n",
      "num_values                     8205\n",
      "Name: 23, dtype: object\n",
      "24\n",
      "chan_id                         A-4\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4550, 4660]]\n",
      "class                  [contextual]\n",
      "num_values                     8080\n",
      "Name: 24, dtype: object\n",
      "25\n",
      "chan_id                         G-1\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4770, 4890]]\n",
      "class                  [contextual]\n",
      "num_values                     8469\n",
      "Name: 25, dtype: object\n",
      "26\n",
      "chan_id                         G-2\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4030, 4070]]\n",
      "class                       [point]\n",
      "num_values                     7361\n",
      "Name: 26, dtype: object\n",
      "27\n",
      "chan_id                         D-5\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4800, 4850]]\n",
      "class                       [point]\n",
      "num_values                     7628\n",
      "Name: 27, dtype: object\n",
      "28\n",
      "chan_id                         D-6\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4870, 4950]]\n",
      "class                       [point]\n",
      "num_values                     7884\n",
      "Name: 28, dtype: object\n",
      "29\n",
      "chan_id                         D-7\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4940, 7641]]\n",
      "class                       [point]\n",
      "num_values                     7642\n",
      "Name: 29, dtype: object\n",
      "30\n",
      "chan_id                         F-1\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5392, 5492]]\n",
      "class                       [point]\n",
      "num_values                     8584\n",
      "Name: 30, dtype: object\n",
      "31\n",
      "chan_id                                                    P-4\n",
      "spacecraft                                                SMAP\n",
      "anomaly_sequences    [[950, 1080], [2150, 2350], [4770, 4880]]\n",
      "class                                    [point, point, point]\n",
      "num_values                                                7783\n",
      "Name: 31, dtype: object\n",
      "32\n",
      "chan_id                         G-3\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4200, 4250]]\n",
      "class                       [point]\n",
      "num_values                     7907\n",
      "Name: 32, dtype: object\n",
      "33\n",
      "chan_id                                       T-1\n",
      "spacecraft                                   SMAP\n",
      "anomaly_sequences    [[2399, 3898], [6550, 6585]]\n",
      "class                         [point, contextual]\n",
      "num_values                                   8612\n",
      "Name: 33, dtype: object\n",
      "34\n",
      "chan_id                         T-2\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[6840, 8624]]\n",
      "class                       [point]\n",
      "num_values                     8625\n",
      "Name: 34, dtype: object\n",
      "35\n",
      "chan_id                         D-8\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4370, 4420]]\n",
      "class                       [point]\n",
      "num_values                     7874\n",
      "Name: 35, dtype: object\n",
      "36\n",
      "chan_id                         D-9\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[6250, 7405]]\n",
      "class                       [point]\n",
      "num_values                     7406\n",
      "Name: 36, dtype: object\n",
      "37\n",
      "chan_id                         F-2\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5669, 8625]]\n",
      "class                       [point]\n",
      "num_values                     8626\n",
      "Name: 37, dtype: object\n",
      "38\n",
      "chan_id                         G-4\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4690, 4720]]\n",
      "class                       [point]\n",
      "num_values                     7632\n",
      "Name: 38, dtype: object\n",
      "39\n",
      "chan_id                                       T-3\n",
      "spacecraft                                   SMAP\n",
      "anomaly_sequences    [[2098, 2180], [5200, 5300]]\n",
      "class                              [point, point]\n",
      "num_values                                   8579\n",
      "Name: 39, dtype: object\n",
      "40\n",
      "chan_id                        D-11\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4270, 4330]]\n",
      "class                       [point]\n",
      "num_values                     7431\n",
      "Name: 40, dtype: object\n",
      "41\n",
      "chan_id                        D-12\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5178, 7917]]\n",
      "class                       [point]\n",
      "num_values                     7918\n",
      "Name: 41, dtype: object\n",
      "42\n",
      "chan_id                         B-1\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5060, 5130]]\n",
      "class                       [point]\n",
      "num_values                     8044\n",
      "Name: 42, dtype: object\n",
      "43\n",
      "chan_id                         G-6\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5600, 5700]]\n",
      "class                       [point]\n",
      "num_values                     8640\n",
      "Name: 43, dtype: object\n",
      "44\n",
      "chan_id                                                     G-7\n",
      "spacecraft                                                 SMAP\n",
      "anomaly_sequences    [[3650, 3750], [5050, 5100], [7560, 7675]]\n",
      "class                           [contextual, point, contextual]\n",
      "num_values                                                 8029\n",
      "Name: 44, dtype: object\n",
      "45\n",
      "chan_id                         P-7\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4950, 6600]]\n",
      "class                  [contextual]\n",
      "num_values                     8071\n",
      "Name: 45, dtype: object\n",
      "46\n",
      "chan_id                         R-1\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4510, 4590]]\n",
      "class                       [point]\n",
      "num_values                     7244\n",
      "Name: 46, dtype: object\n",
      "47\n",
      "chan_id                         A-5\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[2750, 2800]]\n",
      "class                       [point]\n",
      "num_values                     4693\n",
      "Name: 47, dtype: object\n",
      "48\n",
      "chan_id                         A-6\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[1890, 1930]]\n",
      "class                       [point]\n",
      "num_values                     4453\n",
      "Name: 48, dtype: object\n",
      "49\n",
      "chan_id                         A-7\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[6200, 8600]]\n",
      "class                  [contextual]\n",
      "num_values                     8631\n",
      "Name: 49, dtype: object\n",
      "50\n",
      "chan_id                        D-13\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5070, 5230]]\n",
      "class                       [point]\n",
      "num_values                     7663\n",
      "Name: 50, dtype: object\n",
      "51\n",
      "chan_id                         P-2\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5300, 6420]]\n",
      "class                       [point]\n",
      "num_values                     8209\n",
      "Name: 51, dtype: object\n",
      "52\n",
      "chan_id                         A-8\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4569, 8374]]\n",
      "class                  [contextual]\n",
      "num_values                     8375\n",
      "Name: 52, dtype: object\n",
      "53\n",
      "chan_id                         A-9\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[4569, 8433]]\n",
      "class                  [contextual]\n",
      "num_values                     8434\n",
      "Name: 53, dtype: object\n",
      "54\n",
      "chan_id                         F-3\n",
      "spacecraft                     SMAP\n",
      "anomaly_sequences    [[5600, 5640]]\n",
      "class                  [contextual]\n",
      "num_values                     8376\n",
      "Name: 54, dtype: object\n",
      "55\n",
      "chan_id                         M-6\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1850, 2030]]\n",
      "class                       [point]\n",
      "num_values                     2049\n",
      "Name: 55, dtype: object\n",
      "56\n",
      "chan_id                         M-1\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1110, 2250]]\n",
      "class                  [contextual]\n",
      "num_values                     2277\n",
      "Name: 56, dtype: object\n",
      "57\n",
      "chan_id                         M-2\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1110, 2250]]\n",
      "class                  [contextual]\n",
      "num_values                     2277\n",
      "Name: 57, dtype: object\n",
      "58\n",
      "chan_id                       S-2\n",
      "spacecraft                    MSL\n",
      "anomaly_sequences    [[900, 910]]\n",
      "class                     [point]\n",
      "num_values                   1827\n",
      "Name: 58, dtype: object\n",
      "59\n",
      "chan_id                        P-10\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[4590, 4720]]\n",
      "class                       [point]\n",
      "num_values                     6100\n",
      "Name: 59, dtype: object\n",
      "60\n",
      "chan_id                         T-4\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1172, 1240]]\n",
      "class                       [point]\n",
      "num_values                     2217\n",
      "Name: 60, dtype: object\n",
      "61\n",
      "chan_id                         T-5\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1200, 1225]]\n",
      "class                       [point]\n",
      "num_values                     2218\n",
      "Name: 61, dtype: object\n",
      "62\n",
      "chan_id                                                     F-7\n",
      "spacecraft                                                  MSL\n",
      "anomaly_sequences    [[1250, 1450], [2670, 2790], [3325, 3425]]\n",
      "class                      [contextual, contextual, contextual]\n",
      "num_values                                                 5054\n",
      "Name: 62, dtype: object\n",
      "63\n",
      "chan_id                         M-3\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1250, 1500]]\n",
      "class                  [contextual]\n",
      "num_values                     2127\n",
      "Name: 63, dtype: object\n",
      "64\n",
      "chan_id                         M-4\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1250, 1500]]\n",
      "class                  [contextual]\n",
      "num_values                     2038\n",
      "Name: 64, dtype: object\n",
      "65\n",
      "chan_id                         M-5\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1250, 1550]]\n",
      "class                  [contextual]\n",
      "num_values                     2303\n",
      "Name: 65, dtype: object\n",
      "66\n",
      "chan_id                        P-15\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1390, 1410]]\n",
      "class                       [point]\n",
      "num_values                     2856\n",
      "Name: 66, dtype: object\n",
      "67\n",
      "chan_id                                     C-1\n",
      "spacecraft                                  MSL\n",
      "anomaly_sequences    [[550, 750], [2100, 2210]]\n",
      "class                       [point, contextual]\n",
      "num_values                                 2264\n",
      "Name: 67, dtype: object\n",
      "68\n",
      "chan_id                                     C-2\n",
      "spacecraft                                  MSL\n",
      "anomaly_sequences    [[290, 390], [1540, 1575]]\n",
      "class                       [point, contextual]\n",
      "num_values                                 2051\n",
      "Name: 68, dtype: object\n",
      "69\n",
      "chan_id                      T-12\n",
      "spacecraft                    MSL\n",
      "anomaly_sequences    [[630, 750]]\n",
      "class                [contextual]\n",
      "num_values                   2430\n",
      "Name: 69, dtype: object\n",
      "70\n",
      "chan_id                                    T-13\n",
      "spacecraft                                  MSL\n",
      "anomaly_sequences    [[690, 790], [1900, 2050]]\n",
      "class                  [contextual, contextual]\n",
      "num_values                                 2430\n",
      "Name: 70, dtype: object\n",
      "71\n",
      "chan_id                         F-4\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[2700, 2770]]\n",
      "class                       [point]\n",
      "num_values                     3422\n",
      "Name: 71, dtype: object\n",
      "72\n",
      "chan_id                         F-5\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[3550, 3700]]\n",
      "class                       [point]\n",
      "num_values                     3922\n",
      "Name: 72, dtype: object\n",
      "73\n",
      "chan_id                                      D-14\n",
      "spacecraft                                    MSL\n",
      "anomaly_sequences    [[1630, 1650], [1800, 2000]]\n",
      "class                              [point, point]\n",
      "num_values                                   2625\n",
      "Name: 73, dtype: object\n",
      "74\n",
      "chan_id                                   T-9\n",
      "spacecraft                                MSL\n",
      "anomaly_sequences    [[780, 810], [890, 970]]\n",
      "class                          [point, point]\n",
      "num_values                               1096\n",
      "Name: 74, dtype: object\n",
      "75\n",
      "chan_id                        P-14\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[4575, 4755]]\n",
      "class                       [point]\n",
      "num_values                     6100\n",
      "Name: 75, dtype: object\n",
      "76\n",
      "chan_id                                     T-8\n",
      "spacecraft                                  MSL\n",
      "anomaly_sequences    [[870, 930], [1330, 1370]]\n",
      "class                  [contextual, contextual]\n",
      "num_values                                 1519\n",
      "Name: 76, dtype: object\n",
      "77\n",
      "chan_id                                      P-11\n",
      "spacecraft                                    MSL\n",
      "anomaly_sequences    [[1778, 1898], [1238, 1344]]\n",
      "class                              [point, point]\n",
      "num_values                                   3535\n",
      "Name: 77, dtype: object\n",
      "78\n",
      "chan_id                        D-15\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1500, 2140]]\n",
      "class                       [point]\n",
      "num_values                     2158\n",
      "Name: 78, dtype: object\n",
      "79\n",
      "chan_id                       D-16\n",
      "spacecraft                     MSL\n",
      "anomaly_sequences    [[600, 1250]]\n",
      "class                 [contextual]\n",
      "num_values                    2191\n",
      "Name: 79, dtype: object\n",
      "80\n",
      "chan_id                        M-7\n",
      "spacecraft                     MSL\n",
      "anomaly_sequences    [[940, 1040]]\n",
      "class                      [point]\n",
      "num_values                    2156\n",
      "Name: 80, dtype: object\n",
      "81\n",
      "chan_id                         F-8\n",
      "spacecraft                      MSL\n",
      "anomaly_sequences    [[1950, 2486]]\n",
      "class                  [contextual]\n",
      "num_values                     2487\n",
      "Name: 81, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "csv_path = r'C:\\Users\\skhandaker\\OneDrive - Oklahoma City University\\Documents\\Anomaly Detection Paper\\rupa\\archive\\labeled_anomalies.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "anomaly_masks = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(index)\n",
    "    print(row)\n",
    "    chan = row[\"chan_id\"]\n",
    "    num_values = row[\"num_values\"]\n",
    "    intervals = ast.literal_eval(row[\"anomaly_sequences\"])\n",
    "\n",
    "    mask = np.zeros(num_values, dtype=bool)\n",
    "\n",
    "    for start, end in intervals:\n",
    "        mask[start:end+1] = True\n",
    "\n",
    "    anomaly_masks[chan] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc41cf6e-9a97-454b-b281-42f6dabcb418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "context = GPT_CONFIG[\"context_length\"]\n",
    "forecast_horizon = context\n",
    "\n",
    "model.eval()\n",
    "dists, uncertainties, expecteds, y_targets = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(len(val_data) - context - forecast_horizon):\n",
    "    # for t in range(5):\n",
    "        init_seq = val_data[t : t+context, :55].astype(np.float32)\n",
    "        init_seq = init_seq[np.newaxis]\n",
    "        init_seq = torch.tensor(init_seq, device=device)\n",
    "        true_seq = val_data[t+context : t+context+forecast_horizon, :55].astype(np.float32)\n",
    "\n",
    "        # print(pred_emb)\n",
    "        predicted_embs = []\n",
    "        for _ in range(forecast_horizon):\n",
    "            logits = model(init_seq)\n",
    "            next_id = logits[0, -1].argmax().item()\n",
    "            # print(next_id)\n",
    "            pred_emb = emb_tuples[next_id]\n",
    "            # print(pred_emb)\n",
    "            predicted_embs.append(pred_emb)\n",
    "\n",
    "            next_emb = torch.tensor(pred_emb, device=device)\n",
    "            next_emb = next_emb.unsqueeze(0).unsqueeze(0)\n",
    "            init_seq = torch.cat([init_seq, next_emb], dim=1)[:, -context:, :]\n",
    "        dist = np.linalg.norm(predicted_embs - true_seq)\n",
    "        \n",
    "        chan_id = val_data[t, 55]\n",
    "        row_indices = val_data[t+context : t+context+forecast_horizon, 56].astype(int)\n",
    "        mask = anomaly_masks[chan_id]\n",
    "        window_is_anomaly = mask[row_indices].any()\n",
    "        \n",
    "        # print(dist)\n",
    "        # print(window_is_anomaly)\n",
    "        dists.append(dist)\n",
    "        y_targets.append(window_is_anomaly)\n",
    "        # break\n",
    "            \n",
    "const = np.sqrt(2.0 / np.pi)\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Dropout):\n",
    "        m.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(len(val_data) - context - forecast_horizon):\n",
    "    # for t in range(5):\n",
    "        init_seq = val_data[t : t+context, :55].astype(np.float32)\n",
    "        init_seq = init_seq[np.newaxis]\n",
    "        init_seq = torch.tensor(init_seq, device=device)\n",
    "        true_seq = val_data[t+context : t+context+forecast_horizon, :55].astype(np.float32)\n",
    "\n",
    "        # print(pred_emb)\n",
    "        predicted_embs = []\n",
    "        for _ in range(forecast_horizon):\n",
    "        # for _ in range(2):\n",
    "            logits = model(init_seq)\n",
    "            next_id = logits[0, -1].argmax().item()\n",
    "            pred_emb = torch.tensor(emb_tuples[next_id], device=device, dtype=torch.float32)\n",
    "            # print(len(pred_emb))\n",
    "            predicted_embs.append(pred_emb)\n",
    "        # print(predicted_embs)\n",
    "        predicted_embs = torch.vstack(predicted_embs)\n",
    "        uncertainty = predicted_embs.std(0).norm()\n",
    "        uncertainties.append(uncertainty)\n",
    "        expecteds.append(const * uncertainty)\n",
    "        # break\n",
    "\n",
    "# dists should be Python floats  move them to same device\n",
    "d_tensor = torch.tensor(dists, device=device, dtype=torch.float32)\n",
    "\n",
    "# uncertainties and expecteds are lists of CUDA tensors  stack them\n",
    "u_tensor = torch.tensor(uncertainties, device=device, dtype=torch.float32)\n",
    "e_tensor = torch.tensor(expecteds, device=device, dtype=torch.float32)\n",
    "\n",
    "d_norm = (d_tensor - d_tensor.min()) / (d_tensor.max() - d_tensor.min())\n",
    "u_norm = (u_tensor - u_tensor.min()) / (u_tensor.max() - u_tensor.min())\n",
    "e_norm = (e_tensor - e_tensor.min()) / (e_tensor.max() - e_tensor.min())\n",
    "\n",
    "y_preds = d_norm + u_norm + e_norm\n",
    "y_preds = (y_preds > 1.5).to(torch.int)\n",
    "y_preds = y_preds.detach().cpu().numpy()\n",
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8082917c-0af2-47b2-8a04-dad582fd2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import copy\n",
    "\n",
    "##### Evaluation Metrics #####\n",
    "\n",
    "def pak(preds, targets, k=20):\n",
    "\n",
    "    predicts = preds\n",
    "    actuals = targets\n",
    "\n",
    "    one_start_idx = np.where(np.diff(actuals, prepend=0) == 1)[0]\n",
    "    zero_start_idx = np.where(np.diff(actuals, prepend=0) == -1)[0]\n",
    "\n",
    "    assert len(one_start_idx) == len(zero_start_idx) + 1 or len(one_start_idx) == len(zero_start_idx)\n",
    "\n",
    "    if len(one_start_idx) == len(zero_start_idx) + 1:\n",
    "        zero_start_idx = np.append(zero_start_idx, len(predicts))\n",
    "\n",
    "    for i in range(len(one_start_idx)):\n",
    "        if predicts[one_start_idx[i]:zero_start_idx[i]].sum() > k / 100 * (zero_start_idx[i] - one_start_idx[i]):\n",
    "            predicts[one_start_idx[i]:zero_start_idx[i]] = 1\n",
    "\n",
    "    return predicts\n",
    "\n",
    "def get_events(y_test, outlier=1, normal=0):\n",
    "    events = dict()\n",
    "    label_prev = normal\n",
    "    event = 0 \n",
    "    event_start = 0\n",
    "    for tim, label in enumerate(y_test):\n",
    "        if label == outlier:\n",
    "            if label_prev == normal:\n",
    "                event += 1\n",
    "                event_start = tim\n",
    "        else:\n",
    "            if label_prev == outlier:\n",
    "                event_end = tim - 1\n",
    "                events[event] = (event_start, event_end)\n",
    "        label_prev = label\n",
    "\n",
    "    if label_prev == outlier:\n",
    "        event_end = tim - 1\n",
    "        events[event] = (event_start, event_end)\n",
    "    return events\n",
    "\n",
    "def get_composite_fscore_raw(pred_labels, true_events, y_test, return_prec_rec=False):\n",
    "    epsilon = 1e-8\n",
    "    tp = np.sum([pred_labels[start:end + 1].any() for start, end in true_events.values()])\n",
    "    fn = len(true_events) - tp\n",
    "    rec_e = tp/(tp + fn)\n",
    "    prec_t = metrics.precision_score(y_test, pred_labels, zero_division=0)\n",
    "    fscore_c = 2 * rec_e * prec_t / (rec_e + prec_t + epsilon)\n",
    "    if prec_t == 0 and rec_e == 0:\n",
    "        fscore_c = 0\n",
    "    if return_prec_rec:\n",
    "        return prec_t, rec_e, fscore_c\n",
    "    return fscore_c\n",
    "\n",
    "def constant_bias_fn(inputs):\n",
    "\n",
    "    return np.sum(inputs) / inputs.shape[0]\n",
    "\n",
    "def improved_cardinality_fn(cardinality, gt_length):\n",
    "    \n",
    "    return ((gt_length - 1) / gt_length) ** (cardinality - 1)\n",
    "\n",
    "def compute_window_indices(binary_labels):\n",
    "    \n",
    "    boundaries = np.empty_like(binary_labels)\n",
    "    boundaries[0] = 0\n",
    "    boundaries[1:] = binary_labels[:-1]\n",
    "    boundaries *= -1\n",
    "    boundaries += binary_labels\n",
    "\n",
    "    indices = np.nonzero(boundaries)[0].tolist()\n",
    "    if len(indices) % 2 != 0:\n",
    "        indices.append(binary_labels.shape[0])\n",
    "    indices = [(indices[i], indices[i + 1]) for i in range(0, len(indices), 2)]\n",
    "\n",
    "    return indices\n",
    "\n",
    "def _compute_overlap(preds, pred_indices, gt_indices, alpha, bias_fn, cardinality_fn, use_window_weight = False):\n",
    "    n_gt_windows = len(gt_indices)\n",
    "    n_pred_windows = len(pred_indices)\n",
    "    total_score = 0.0\n",
    "    total_gt_points = 0\n",
    "\n",
    "    i = j = 0\n",
    "    while i < n_gt_windows and j < n_pred_windows:\n",
    "        gt_start, gt_end = gt_indices[i]\n",
    "        window_length = gt_end - gt_start\n",
    "        total_gt_points += window_length\n",
    "        i += 1\n",
    "\n",
    "        cardinality = 0\n",
    "        while j < n_pred_windows and pred_indices[j][1] <= gt_start:\n",
    "            j += 1\n",
    "        while j < n_pred_windows and pred_indices[j][0] < gt_end:\n",
    "            j += 1\n",
    "            cardinality += 1\n",
    "\n",
    "        if cardinality == 0:\n",
    "            continue\n",
    "        \n",
    "        j -= 1\n",
    "\n",
    "        cardinality_multiplier = cardinality_fn(cardinality, window_length)\n",
    "\n",
    "        prediction_inside_ground_truth = preds[gt_start:gt_end]\n",
    "        omega = bias_fn(prediction_inside_ground_truth)\n",
    "\n",
    "        weight = window_length if use_window_weight else 1\n",
    "\n",
    "        total_score += alpha * weight\n",
    "        total_score += (1 - alpha) * cardinality_multiplier * omega * weight\n",
    "\n",
    "    denom = total_gt_points if use_window_weight else n_gt_windows\n",
    "\n",
    "    return total_score / denom\n",
    "\n",
    "def ts_precision_and_recall(anomalies, predictions, alpha = 0,\n",
    "                            recall_bias_fn = constant_bias_fn,\n",
    "                            recall_cardinality_fn = improved_cardinality_fn,\n",
    "                            precision_bias_fn = None,\n",
    "                            precision_cardinality_fn = None,\n",
    "                            anomaly_ranges = None,\n",
    "                            prediction_ranges = None,\n",
    "                            weighted_precision = False):\n",
    "    has_anomalies = np.any(anomalies > 0)\n",
    "    has_predictions = np.any(predictions > 0)\n",
    "\n",
    "    if not has_predictions and not has_anomalies:\n",
    "        return 1, 1\n",
    "    elif not has_predictions or not has_anomalies:\n",
    "        return 0, 0\n",
    "\n",
    "    if precision_bias_fn is None:\n",
    "        precision_bias_fn = recall_bias_fn\n",
    "    if precision_cardinality_fn is None:\n",
    "        precision_cardinality_fn = recall_cardinality_fn\n",
    "\n",
    "    if anomaly_ranges is None:\n",
    "        anomaly_ranges = compute_window_indices(anomalies)\n",
    "    if prediction_ranges is None:\n",
    "        prediction_ranges = compute_window_indices(predictions)\n",
    "\n",
    "    recall = _compute_overlap(predictions, prediction_ranges, anomaly_ranges, alpha, recall_bias_fn,\n",
    "                              recall_cardinality_fn)\n",
    "    precision = _compute_overlap(anomalies, anomaly_ranges, prediction_ranges, 0, precision_bias_fn,\n",
    "                                 precision_cardinality_fn, use_window_weight=weighted_precision)\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "class ano_evaluator:\n",
    "    def __init__(self, preds, targets = None):\n",
    "        assert len(preds) == len(targets)\n",
    "        \n",
    "        try:\n",
    "            preds = np.asarray(preds)\n",
    "            targets = np.asarray(targets)\n",
    "        except TypeError:\n",
    "            preds = np.asarray(preds.cpu())\n",
    "            targets = np.asarray(targets.cpu())\n",
    "            \n",
    "        self.targets = targets\n",
    "        self.preds = preds\n",
    "        \n",
    "    def eval_naive_f1(self):\n",
    "        f1 = metrics.f1_score(self.targets, self.preds, zero_division = 0)\n",
    "        prec = metrics.precision_score(self.targets, self.preds, zero_division=0)\n",
    "        recall = metrics.recall_score(self.targets, self.preds, zero_division=0)\n",
    "        return f1, prec, recall\n",
    "        \n",
    "    def eval_pak_auc(self):\n",
    "        pak_metrics_list = []\n",
    "        for k in np.arange(0,110, 10):\n",
    "            preds_new = copy.deepcopy(self.preds)\n",
    "            targets_new = copy.deepcopy(self.targets)\n",
    "            pa_scores = pak(preds_new, targets_new, k)\n",
    "            pak_metrics_list.append([metrics.f1_score(targets_new, pa_scores, zero_division = 0),\n",
    "                                     metrics.precision_score(targets_new, pa_scores, zero_division=0),\n",
    "                                     metrics.recall_score(targets_new, pa_scores, zero_division=0),\n",
    "                                     ])\n",
    "        pak_metrics = np.array(pak_metrics_list)\n",
    "        f1_pak_auc = metrics.auc(np.arange(0,110, 10), pak_metrics[:,0]) / 100.0\n",
    "        prec_pak_auc = metrics.auc(np.arange(0,110, 10), pak_metrics[:,1]) / 100.0\n",
    "        recall_pak_auc = metrics.auc(np.arange(0,110, 10), pak_metrics[:,2]) / 100.0\n",
    "\n",
    "        return f1_pak_auc, prec_pak_auc, recall_pak_auc\n",
    "    \n",
    "    def eval_f1_composite(self):\n",
    "        true_events = get_events(self.targets)\n",
    "        prec_pw, rec_ew, f1_comp = get_composite_fscore_raw(self.preds, true_events, self.targets, return_prec_rec=True)\n",
    "        return f1_comp, prec_pw, rec_ew\n",
    "    \n",
    "    def eval_f1_range(self):\n",
    "        epsilon = 1e-8\n",
    "        label_ranges = compute_window_indices(self.targets)\n",
    "        prec, recall = ts_precision_and_recall(self.targets, self.preds, alpha=0,\n",
    "                                                anomaly_ranges=label_ranges,\n",
    "                                                weighted_precision=True)\n",
    "        f1 = (1 + 1**2) * prec * recall / (1**2 * prec + recall + epsilon) \n",
    "        return f1, prec, recall\n",
    "\n",
    "def return_scores(evaluator):\n",
    "    result_f1, prec, rec = evaluator.eval_naive_f1()\n",
    "    result_f1, prec, rec = round(result_f1, 5), round(prec, 5),round(rec, 5)\n",
    "    \n",
    "    result_f1_pak, pre_pak, rec_pak = evaluator.eval_pak_auc()\n",
    "    result_f1_pak, pre_pak, rec_pak = round(result_f1_pak, 5), round(pre_pak, 5),round(rec_pak, 5)\n",
    "    \n",
    "    result_f1_comp, pre_comp, rec_comp = evaluator.eval_f1_composite()\n",
    "    result_f1_comp, pre_comp, rec_comp = round(result_f1_comp, 5), round(pre_comp, 5),round(rec_comp, 5)\n",
    "    \n",
    "    result_f1_range, pre_range, rec_range = evaluator.eval_f1_range()\n",
    "    result_f1_range, pre_range, rec_range = round(result_f1_range, 5), round(pre_range, 5),round(rec_range, 5)\n",
    "    \n",
    "    return result_f1, prec, rec, result_f1_pak, pre_pak, rec_pak, result_f1_comp, pre_comp, rec_comp, result_f1_range, pre_range, rec_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "624a43e7-411c-4ed8-9ef4-02180838dff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point-wise F1: 0.02618\n",
      "Point-wise Precision: 0.65789\n",
      "Point-wise Recall: 0.01335\n",
      "F1-k (PAK): 0.06321\n",
      "Precision-k: 0.67445\n",
      "Recall-k: 0.04399\n",
      "F1-c (Composite): 0.56818\n",
      "Precision-c: 0.65789\n",
      "Recall-c: 0.5\n",
      "F1-r (Range): 0.025\n",
      "Precision-r: 0.65789\n",
      "Recall-r: 0.01274\n"
     ]
    }
   ],
   "source": [
    "y_preds = np.asarray(y_preds, dtype=int)\n",
    "y_targets = np.asarray(y_targets, dtype=int)\n",
    "\n",
    "evaluator = ano_evaluator(y_preds, y_targets)\n",
    "\n",
    "f1, precision, recall, f1_k, precision_k, recall_k, f1_c, precision_c, recall_c, f1_r, precision_r, recall_r = return_scores(evaluator)\n",
    "print(\"Point-wise F1:\", f1)\n",
    "print(\"Point-wise Precision:\", precision)\n",
    "print(\"Point-wise Recall:\", recall)\n",
    "\n",
    "print(\"F1-k (PAK):\", f1_k)\n",
    "print(\"Precision-k:\", precision_k)\n",
    "print(\"Recall-k:\", recall_k)\n",
    "\n",
    "print(\"F1-c (Composite):\", f1_c)\n",
    "print(\"Precision-c:\", precision_c)\n",
    "print(\"Recall-c:\", recall_c)\n",
    "\n",
    "print(\"F1-r (Range):\", f1_r)\n",
    "print(\"Precision-r:\", precision_r)\n",
    "print(\"Recall-r:\", recall_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4158b-7716-424c-8625-97da409d89b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anomaly)",
   "language": "python",
   "name": "anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
